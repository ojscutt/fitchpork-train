{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6003cdb-3f99-42f3-8d34-c866370496bc",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec18f37-d27a-45aa-93e2-98350e4b18c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 11:04:04.891588: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-01-23 11:04:04.891616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-01-23 11:04:04.892731: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-01-23 11:04:04.898235: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-23 11:04:05.418145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU usage:\n",
      " - GPU0: 0B\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 11:04:06.084246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18447 MB memory:  -> device: 0, name: NVIDIA RTX A4500, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "## ML imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from scripts import WMSE, InversePCA\n",
    "\n",
    "## other imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "##### poke gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\") \n",
    "\n",
    "gpu0usage = tf.config.experimental.get_memory_info(\"GPU:0\")[\"current\"]\n",
    "\n",
    "print(\"Current GPU usage:\\n\"\n",
    "     + \" - GPU0: \" + str(gpu0usage) + \"B\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db8a6ac-8192-4766-89bc-aba8de007870",
   "metadata": {},
   "source": [
    "## load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180d7ffd-eaf6-43e1-af3c-6054c7b9bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## def data dir\n",
    "repo_dir = '/home/oxs235/datastorage/repos_data/ojscutt/fitchpork-train/'\n",
    "\n",
    "data_dir = repo_dir + 'data/'\n",
    "\n",
    "## load in train and validation\n",
    "df_train = pd.read_hdf(data_dir+'bob_train_slim_fp.h5', key='df')\n",
    "df_val = pd.read_hdf(data_dir+'bob_val_slim_fp.h5', key='df')\n",
    "\n",
    "## load in PCA variables\n",
    "pca_mean = np.loadtxt(data_dir+'pca_mean_fp.csv')\n",
    "pca_components = np.loadtxt(data_dir+'pca_components_fp.csv')\n",
    "\n",
    "## load in WMSE weights\n",
    "WMSE_weights = np.loadtxt(data_dir+'WMSE_weights_fp.csv').tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbb47f-d727-4ac1-9025-ce206e2f3bc0",
   "metadata": {},
   "source": [
    "## define inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f9050c-5e46-4590-8e7e-a14bf5222ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define inputs\n",
    "inputs = ['log_initial_mass_std', 'log_initial_Zinit_std', 'log_initial_Yinit_std', 'log_initial_MLT_std', 'log_star_age_std']\n",
    "\n",
    "#### define outputs\n",
    "classical_outputs = ['log_radius_std', 'log_luminosity_std', 'star_feh_std']\n",
    "astero_outputs = [f'log_nu_0_{i+1}_std' for i in range(5,40)]\n",
    "\n",
    "outputs = classical_outputs+astero_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d3dce-c123-41ab-b625-89c638282d5a",
   "metadata": {},
   "source": [
    "# train pitchfork!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03753d16-55f8-4359-9a3f-6d0ee6c13379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 11:04:12.276536: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-23 11:04:13.924875: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ef0918e3a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2026-01-23 11:04:13.924914: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A4500, Compute Capability 8.6\n",
      "2026-01-23 11:04:13.929886: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2026-01-23 11:04:13.943007: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1769166254.023057 1266698 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 3s 14ms/step - loss: 28717744.0000 - classical_outs_loss: 969.1381 - inverse_pca_loss: 28716770.0000 - val_loss: 6253324.0000 - val_classical_outs_loss: 326.9517 - val_inverse_pca_loss: 6252996.5000 - lr: 9.9994e-04\n",
      "Epoch 2/100000\n",
      "15/68 [=====>........................] - ETA: 0s - loss: 5314307.5000 - classical_outs_loss: 305.5121 - inverse_pca_loss: 5314002.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oxs235/miniconda3/envs/py311tf215/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 10ms/step - loss: 4117332.2500 - classical_outs_loss: 257.2847 - inverse_pca_loss: 4117075.7500 - val_loss: 3210188.7500 - val_classical_outs_loss: 212.0863 - val_inverse_pca_loss: 3209976.5000 - lr: 9.9988e-04\n",
      "Epoch 3/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 2423616.2500 - classical_outs_loss: 191.7865 - inverse_pca_loss: 2423425.0000 - val_loss: 1891293.2500 - val_classical_outs_loss: 170.6600 - val_inverse_pca_loss: 1891122.6250 - lr: 9.9982e-04\n",
      "Epoch 4/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 2531459.2500 - classical_outs_loss: 156.3691 - inverse_pca_loss: 2531302.7500 - val_loss: 1954717.0000 - val_classical_outs_loss: 139.4935 - val_inverse_pca_loss: 1954577.2500 - lr: 9.9976e-04\n",
      "Epoch 5/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2148129.5000 - classical_outs_loss: 129.2208 - inverse_pca_loss: 2148000.7500 - val_loss: 3153658.5000 - val_classical_outs_loss: 118.1590 - val_inverse_pca_loss: 3153540.2500 - lr: 9.9970e-04\n",
      "Epoch 6/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1688759.2500 - classical_outs_loss: 110.3721 - inverse_pca_loss: 1688648.6250 - val_loss: 1351044.7500 - val_classical_outs_loss: 101.9583 - val_inverse_pca_loss: 1350942.7500 - lr: 9.9964e-04\n",
      "Epoch 7/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 2093011.6250 - classical_outs_loss: 97.5368 - inverse_pca_loss: 2092914.0000 - val_loss: 1475102.6250 - val_classical_outs_loss: 91.0780 - val_inverse_pca_loss: 1475011.5000 - lr: 9.9958e-04\n",
      "Epoch 8/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1491681.2500 - classical_outs_loss: 87.9736 - inverse_pca_loss: 1491592.7500 - val_loss: 1472694.6250 - val_classical_outs_loss: 83.3977 - val_inverse_pca_loss: 1472611.2500 - lr: 9.9952e-04\n",
      "Epoch 9/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1570443.5000 - classical_outs_loss: 81.3831 - inverse_pca_loss: 1570361.8750 - val_loss: 1388375.5000 - val_classical_outs_loss: 77.8603 - val_inverse_pca_loss: 1388297.6250 - lr: 9.9946e-04\n",
      "Epoch 10/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1431116.1250 - classical_outs_loss: 76.1517 - inverse_pca_loss: 1431040.2500 - val_loss: 1550068.3750 - val_classical_outs_loss: 73.1694 - val_inverse_pca_loss: 1549995.3750 - lr: 9.9940e-04\n",
      "Epoch 11/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1421658.8750 - classical_outs_loss: 71.9202 - inverse_pca_loss: 1421586.8750 - val_loss: 1383865.3750 - val_classical_outs_loss: 69.5318 - val_inverse_pca_loss: 1383796.0000 - lr: 9.9934e-04\n",
      "Epoch 12/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1410654.0000 - classical_outs_loss: 68.1624 - inverse_pca_loss: 1410585.6250 - val_loss: 2128508.2500 - val_classical_outs_loss: 66.4299 - val_inverse_pca_loss: 2128441.5000 - lr: 9.9928e-04\n",
      "Epoch 13/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1395648.8750 - classical_outs_loss: 64.7493 - inverse_pca_loss: 1395584.2500 - val_loss: 1303196.5000 - val_classical_outs_loss: 62.7521 - val_inverse_pca_loss: 1303133.7500 - lr: 9.9922e-04\n",
      "Epoch 14/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1301204.2500 - classical_outs_loss: 61.6619 - inverse_pca_loss: 1301142.5000 - val_loss: 1435824.8750 - val_classical_outs_loss: 59.9101 - val_inverse_pca_loss: 1435764.8750 - lr: 9.9916e-04\n",
      "Epoch 15/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1381423.8750 - classical_outs_loss: 59.1721 - inverse_pca_loss: 1381364.8750 - val_loss: 1220921.6250 - val_classical_outs_loss: 57.3409 - val_inverse_pca_loss: 1220864.2500 - lr: 9.9910e-04\n",
      "Epoch 16/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1344802.5000 - classical_outs_loss: 56.7219 - inverse_pca_loss: 1344745.8750 - val_loss: 1175720.0000 - val_classical_outs_loss: 55.2047 - val_inverse_pca_loss: 1175664.7500 - lr: 9.9904e-04\n",
      "Epoch 17/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1312000.7500 - classical_outs_loss: 54.6058 - inverse_pca_loss: 1311946.3750 - val_loss: 1233272.3750 - val_classical_outs_loss: 52.9399 - val_inverse_pca_loss: 1233219.3750 - lr: 9.9898e-04\n",
      "Epoch 18/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1277051.3750 - classical_outs_loss: 52.6746 - inverse_pca_loss: 1276998.7500 - val_loss: 2014265.3750 - val_classical_outs_loss: 52.1351 - val_inverse_pca_loss: 2014213.3750 - lr: 9.9892e-04\n",
      "Epoch 19/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1322752.7500 - classical_outs_loss: 51.4230 - inverse_pca_loss: 1322701.5000 - val_loss: 1252975.6250 - val_classical_outs_loss: 49.5809 - val_inverse_pca_loss: 1252926.1250 - lr: 9.9886e-04\n",
      "Epoch 20/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1254835.3750 - classical_outs_loss: 49.4203 - inverse_pca_loss: 1254785.7500 - val_loss: 1150484.0000 - val_classical_outs_loss: 47.8222 - val_inverse_pca_loss: 1150436.1250 - lr: 9.9880e-04\n",
      "Epoch 21/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1260312.1250 - classical_outs_loss: 48.1249 - inverse_pca_loss: 1260264.1250 - val_loss: 1141857.2500 - val_classical_outs_loss: 46.7987 - val_inverse_pca_loss: 1141810.5000 - lr: 9.9874e-04\n",
      "Epoch 22/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1256498.0000 - classical_outs_loss: 46.9944 - inverse_pca_loss: 1256450.8750 - val_loss: 1091723.0000 - val_classical_outs_loss: 45.2059 - val_inverse_pca_loss: 1091677.7500 - lr: 9.9868e-04\n",
      "Epoch 23/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1251173.7500 - classical_outs_loss: 45.3497 - inverse_pca_loss: 1251128.3750 - val_loss: 1124067.7500 - val_classical_outs_loss: 44.6115 - val_inverse_pca_loss: 1124023.1250 - lr: 9.9862e-04\n",
      "Epoch 24/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1243068.6250 - classical_outs_loss: 44.0237 - inverse_pca_loss: 1243024.7500 - val_loss: 1381929.1250 - val_classical_outs_loss: 43.4210 - val_inverse_pca_loss: 1381885.6250 - lr: 9.9856e-04\n",
      "Epoch 25/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1209038.6250 - classical_outs_loss: 42.8416 - inverse_pca_loss: 1208996.2500 - val_loss: 1381191.2500 - val_classical_outs_loss: 41.9401 - val_inverse_pca_loss: 1381149.1250 - lr: 9.9850e-04\n",
      "Epoch 26/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1202787.3750 - classical_outs_loss: 41.6946 - inverse_pca_loss: 1202745.8750 - val_loss: 1267880.0000 - val_classical_outs_loss: 40.0145 - val_inverse_pca_loss: 1267839.8750 - lr: 9.9844e-04\n",
      "Epoch 27/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1333016.8750 - classical_outs_loss: 40.6900 - inverse_pca_loss: 1332976.0000 - val_loss: 1270350.2500 - val_classical_outs_loss: 39.7228 - val_inverse_pca_loss: 1270310.5000 - lr: 9.9838e-04\n",
      "Epoch 28/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1187824.7500 - classical_outs_loss: 39.6091 - inverse_pca_loss: 1187785.2500 - val_loss: 1251505.7500 - val_classical_outs_loss: 38.5953 - val_inverse_pca_loss: 1251467.1250 - lr: 9.9832e-04\n",
      "Epoch 29/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1147430.2500 - classical_outs_loss: 38.4367 - inverse_pca_loss: 1147391.7500 - val_loss: 1308143.2500 - val_classical_outs_loss: 37.1619 - val_inverse_pca_loss: 1308106.0000 - lr: 9.9826e-04\n",
      "Epoch 30/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 1165259.8750 - classical_outs_loss: 36.8367 - inverse_pca_loss: 1165223.1250 - val_loss: 1154717.5000 - val_classical_outs_loss: 35.7083 - val_inverse_pca_loss: 1154681.7500 - lr: 9.9820e-04\n",
      "Epoch 31/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1186082.5000 - classical_outs_loss: 35.6807 - inverse_pca_loss: 1186047.0000 - val_loss: 1074466.2500 - val_classical_outs_loss: 34.2855 - val_inverse_pca_loss: 1074431.8750 - lr: 9.9814e-04\n",
      "Epoch 32/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1165538.6250 - classical_outs_loss: 35.2703 - inverse_pca_loss: 1165503.2500 - val_loss: 1176117.8750 - val_classical_outs_loss: 33.7548 - val_inverse_pca_loss: 1176084.0000 - lr: 9.9808e-04\n",
      "Epoch 33/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1146506.8750 - classical_outs_loss: 33.6610 - inverse_pca_loss: 1146473.0000 - val_loss: 1136966.1250 - val_classical_outs_loss: 32.4840 - val_inverse_pca_loss: 1136933.6250 - lr: 9.9802e-04\n",
      "Epoch 34/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1140257.0000 - classical_outs_loss: 32.4916 - inverse_pca_loss: 1140224.3750 - val_loss: 1268682.6250 - val_classical_outs_loss: 31.8736 - val_inverse_pca_loss: 1268650.7500 - lr: 9.9796e-04\n",
      "Epoch 35/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1104007.5000 - classical_outs_loss: 31.5543 - inverse_pca_loss: 1103976.0000 - val_loss: 932578.9375 - val_classical_outs_loss: 30.5272 - val_inverse_pca_loss: 932548.3750 - lr: 9.9790e-04\n",
      "Epoch 36/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1108957.8750 - classical_outs_loss: 31.0915 - inverse_pca_loss: 1108926.5000 - val_loss: 1588948.8750 - val_classical_outs_loss: 30.6175 - val_inverse_pca_loss: 1588918.3750 - lr: 9.9784e-04\n",
      "Epoch 37/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1139316.1250 - classical_outs_loss: 30.6149 - inverse_pca_loss: 1139285.5000 - val_loss: 1171215.5000 - val_classical_outs_loss: 29.5908 - val_inverse_pca_loss: 1171185.8750 - lr: 9.9778e-04\n",
      "Epoch 38/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1109093.1250 - classical_outs_loss: 29.3804 - inverse_pca_loss: 1109063.8750 - val_loss: 1146509.8750 - val_classical_outs_loss: 31.0332 - val_inverse_pca_loss: 1146479.0000 - lr: 9.9772e-04\n",
      "Epoch 39/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1055131.1250 - classical_outs_loss: 29.3620 - inverse_pca_loss: 1055101.6250 - val_loss: 1388057.5000 - val_classical_outs_loss: 29.2410 - val_inverse_pca_loss: 1388028.2500 - lr: 9.9766e-04\n",
      "Epoch 40/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1118620.7500 - classical_outs_loss: 28.5104 - inverse_pca_loss: 1118592.5000 - val_loss: 1652821.0000 - val_classical_outs_loss: 29.2848 - val_inverse_pca_loss: 1652791.7500 - lr: 9.9760e-04\n",
      "Epoch 41/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1014035.9375 - classical_outs_loss: 27.6799 - inverse_pca_loss: 1014008.0625 - val_loss: 1376307.5000 - val_classical_outs_loss: 30.5069 - val_inverse_pca_loss: 1376276.8750 - lr: 9.9754e-04\n",
      "Epoch 42/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 1048579.7500 - classical_outs_loss: 27.5620 - inverse_pca_loss: 1048552.0625 - val_loss: 813286.7500 - val_classical_outs_loss: 27.8451 - val_inverse_pca_loss: 813258.8750 - lr: 9.9748e-04\n",
      "Epoch 43/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 1000552.8750 - classical_outs_loss: 27.4096 - inverse_pca_loss: 1000525.1875 - val_loss: 772801.1875 - val_classical_outs_loss: 26.0040 - val_inverse_pca_loss: 772775.1250 - lr: 9.9742e-04\n",
      "Epoch 44/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 1006736.7500 - classical_outs_loss: 26.5030 - inverse_pca_loss: 1006710.1250 - val_loss: 1353645.5000 - val_classical_outs_loss: 25.9373 - val_inverse_pca_loss: 1353619.5000 - lr: 9.9736e-04\n",
      "Epoch 45/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 935085.0625 - classical_outs_loss: 26.4554 - inverse_pca_loss: 935058.7500 - val_loss: 1390906.6250 - val_classical_outs_loss: 25.7360 - val_inverse_pca_loss: 1390881.0000 - lr: 9.9731e-04\n",
      "Epoch 46/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 940341.8125 - classical_outs_loss: 25.2876 - inverse_pca_loss: 940316.4375 - val_loss: 1057940.5000 - val_classical_outs_loss: 26.4792 - val_inverse_pca_loss: 1057914.0000 - lr: 9.9725e-04\n",
      "Epoch 47/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 892417.0000 - classical_outs_loss: 25.3360 - inverse_pca_loss: 892392.0000 - val_loss: 916827.9375 - val_classical_outs_loss: 25.4355 - val_inverse_pca_loss: 916802.4375 - lr: 9.9719e-04\n",
      "Epoch 48/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 843294.8125 - classical_outs_loss: 24.9324 - inverse_pca_loss: 843270.0000 - val_loss: 1028331.5000 - val_classical_outs_loss: 23.9437 - val_inverse_pca_loss: 1028307.5625 - lr: 9.9713e-04\n",
      "Epoch 49/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 950900.2500 - classical_outs_loss: 24.7810 - inverse_pca_loss: 950875.3125 - val_loss: 879131.6875 - val_classical_outs_loss: 24.0528 - val_inverse_pca_loss: 879107.6875 - lr: 9.9707e-04\n",
      "Epoch 50/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 806496.8750 - classical_outs_loss: 24.1026 - inverse_pca_loss: 806472.8125 - val_loss: 902527.6875 - val_classical_outs_loss: 25.0504 - val_inverse_pca_loss: 902502.6875 - lr: 9.9701e-04\n",
      "Epoch 51/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 779163.2500 - classical_outs_loss: 23.4699 - inverse_pca_loss: 779139.6875 - val_loss: 662407.8750 - val_classical_outs_loss: 22.5175 - val_inverse_pca_loss: 662385.2500 - lr: 9.9695e-04\n",
      "Epoch 52/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 715185.0000 - classical_outs_loss: 23.9167 - inverse_pca_loss: 715161.1875 - val_loss: 848205.0000 - val_classical_outs_loss: 23.4601 - val_inverse_pca_loss: 848181.5625 - lr: 9.9689e-04\n",
      "Epoch 53/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 806144.0625 - classical_outs_loss: 23.1204 - inverse_pca_loss: 806121.2500 - val_loss: 763950.5000 - val_classical_outs_loss: 22.3189 - val_inverse_pca_loss: 763928.2500 - lr: 9.9683e-04\n",
      "Epoch 54/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 736406.6875 - classical_outs_loss: 22.6072 - inverse_pca_loss: 736383.8125 - val_loss: 519941.5312 - val_classical_outs_loss: 21.8756 - val_inverse_pca_loss: 519919.6875 - lr: 9.9677e-04\n",
      "Epoch 55/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 655817.7500 - classical_outs_loss: 22.3446 - inverse_pca_loss: 655795.4375 - val_loss: 550542.5000 - val_classical_outs_loss: 22.8839 - val_inverse_pca_loss: 550519.6875 - lr: 9.9671e-04\n",
      "Epoch 56/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 711781.0625 - classical_outs_loss: 21.8858 - inverse_pca_loss: 711759.3125 - val_loss: 538958.3750 - val_classical_outs_loss: 21.0050 - val_inverse_pca_loss: 538937.3125 - lr: 9.9665e-04\n",
      "Epoch 57/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 735859.6875 - classical_outs_loss: 22.0712 - inverse_pca_loss: 735837.5625 - val_loss: 694860.1875 - val_classical_outs_loss: 22.8249 - val_inverse_pca_loss: 694837.3750 - lr: 9.9659e-04\n",
      "Epoch 58/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 632215.1875 - classical_outs_loss: 21.4663 - inverse_pca_loss: 632193.6875 - val_loss: 806639.5625 - val_classical_outs_loss: 20.7490 - val_inverse_pca_loss: 806618.7500 - lr: 9.9653e-04\n",
      "Epoch 59/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 683173.2500 - classical_outs_loss: 20.8043 - inverse_pca_loss: 683152.3750 - val_loss: 519564.2812 - val_classical_outs_loss: 21.1984 - val_inverse_pca_loss: 519543.1250 - lr: 9.9647e-04\n",
      "Epoch 60/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 676541.3750 - classical_outs_loss: 21.0213 - inverse_pca_loss: 676520.1250 - val_loss: 522139.0938 - val_classical_outs_loss: 19.8795 - val_inverse_pca_loss: 522119.2188 - lr: 9.9641e-04\n",
      "Epoch 61/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 605356.8125 - classical_outs_loss: 20.4671 - inverse_pca_loss: 605336.2500 - val_loss: 511439.4375 - val_classical_outs_loss: 19.3132 - val_inverse_pca_loss: 511420.0938 - lr: 9.9635e-04\n",
      "Epoch 62/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 625993.8750 - classical_outs_loss: 19.6354 - inverse_pca_loss: 625974.3125 - val_loss: 717900.6250 - val_classical_outs_loss: 19.3946 - val_inverse_pca_loss: 717881.3750 - lr: 9.9629e-04\n",
      "Epoch 63/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 566957.5625 - classical_outs_loss: 19.8796 - inverse_pca_loss: 566937.6250 - val_loss: 857548.3125 - val_classical_outs_loss: 19.3807 - val_inverse_pca_loss: 857528.9375 - lr: 9.9623e-04\n",
      "Epoch 64/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 654215.5000 - classical_outs_loss: 19.5964 - inverse_pca_loss: 654195.8125 - val_loss: 648934.1875 - val_classical_outs_loss: 18.6568 - val_inverse_pca_loss: 648915.5000 - lr: 9.9617e-04\n",
      "Epoch 65/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 599378.7500 - classical_outs_loss: 19.0215 - inverse_pca_loss: 599359.8750 - val_loss: 589018.4375 - val_classical_outs_loss: 18.2717 - val_inverse_pca_loss: 589000.1250 - lr: 9.9611e-04\n",
      "Epoch 66/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 549701.4375 - classical_outs_loss: 18.8815 - inverse_pca_loss: 549682.5625 - val_loss: 619893.1875 - val_classical_outs_loss: 18.1556 - val_inverse_pca_loss: 619875.0000 - lr: 9.9605e-04\n",
      "Epoch 67/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 627080.1875 - classical_outs_loss: 19.0006 - inverse_pca_loss: 627060.9375 - val_loss: 539312.1875 - val_classical_outs_loss: 19.9620 - val_inverse_pca_loss: 539292.2500 - lr: 9.9599e-04\n",
      "Epoch 68/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 572258.5000 - classical_outs_loss: 18.3521 - inverse_pca_loss: 572240.1250 - val_loss: 465963.5312 - val_classical_outs_loss: 17.3169 - val_inverse_pca_loss: 465946.2500 - lr: 9.9593e-04\n",
      "Epoch 69/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 583082.6250 - classical_outs_loss: 17.8847 - inverse_pca_loss: 583064.7500 - val_loss: 501678.3750 - val_classical_outs_loss: 18.1640 - val_inverse_pca_loss: 501660.2188 - lr: 9.9587e-04\n",
      "Epoch 70/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 563860.9375 - classical_outs_loss: 17.6646 - inverse_pca_loss: 563843.3125 - val_loss: 471318.9375 - val_classical_outs_loss: 18.2626 - val_inverse_pca_loss: 471300.6562 - lr: 9.9581e-04\n",
      "Epoch 71/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 523250.8125 - classical_outs_loss: 17.5295 - inverse_pca_loss: 523233.3750 - val_loss: 662856.8125 - val_classical_outs_loss: 17.2253 - val_inverse_pca_loss: 662839.6250 - lr: 9.9575e-04\n",
      "Epoch 72/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 514552.9375 - classical_outs_loss: 16.8862 - inverse_pca_loss: 514536.0938 - val_loss: 392904.4062 - val_classical_outs_loss: 16.7904 - val_inverse_pca_loss: 392887.6250 - lr: 9.9569e-04\n",
      "Epoch 73/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 502943.7812 - classical_outs_loss: 16.8669 - inverse_pca_loss: 502926.7812 - val_loss: 736581.5000 - val_classical_outs_loss: 18.2987 - val_inverse_pca_loss: 736563.1875 - lr: 9.9563e-04\n",
      "Epoch 74/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 547297.4375 - classical_outs_loss: 16.9952 - inverse_pca_loss: 547280.4375 - val_loss: 540618.1875 - val_classical_outs_loss: 15.9961 - val_inverse_pca_loss: 540602.1875 - lr: 9.9557e-04\n",
      "Epoch 75/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 477780.6562 - classical_outs_loss: 16.6744 - inverse_pca_loss: 477764.0312 - val_loss: 584025.8750 - val_classical_outs_loss: 15.5672 - val_inverse_pca_loss: 584010.2500 - lr: 9.9551e-04\n",
      "Epoch 76/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 498965.3750 - classical_outs_loss: 16.1120 - inverse_pca_loss: 498949.3125 - val_loss: 446131.0312 - val_classical_outs_loss: 15.8424 - val_inverse_pca_loss: 446115.1562 - lr: 9.9545e-04\n",
      "Epoch 77/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 838356.3125 - classical_outs_loss: 19.0634 - inverse_pca_loss: 838337.1875 - val_loss: 864709.9375 - val_classical_outs_loss: 16.9256 - val_inverse_pca_loss: 864693.0625 - lr: 9.9539e-04\n",
      "Epoch 78/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 437754.6562 - classical_outs_loss: 15.9987 - inverse_pca_loss: 437738.8125 - val_loss: 461598.7188 - val_classical_outs_loss: 15.5976 - val_inverse_pca_loss: 461583.1250 - lr: 9.9533e-04\n",
      "Epoch 79/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 537242.9375 - classical_outs_loss: 16.4484 - inverse_pca_loss: 537226.6250 - val_loss: 698728.7500 - val_classical_outs_loss: 15.1812 - val_inverse_pca_loss: 698713.5625 - lr: 9.9527e-04\n",
      "Epoch 80/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 431018.5625 - classical_outs_loss: 14.6194 - inverse_pca_loss: 431003.9688 - val_loss: 296702.7812 - val_classical_outs_loss: 14.3291 - val_inverse_pca_loss: 296688.4375 - lr: 9.9521e-04\n",
      "Epoch 81/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 463266.2812 - classical_outs_loss: 15.3748 - inverse_pca_loss: 463250.9062 - val_loss: 462572.4375 - val_classical_outs_loss: 14.5810 - val_inverse_pca_loss: 462557.8750 - lr: 9.9515e-04\n",
      "Epoch 82/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 470490.0312 - classical_outs_loss: 14.7598 - inverse_pca_loss: 470475.2812 - val_loss: 344277.9688 - val_classical_outs_loss: 13.8520 - val_inverse_pca_loss: 344264.0938 - lr: 9.9509e-04\n",
      "Epoch 83/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 486702.4375 - classical_outs_loss: 15.1812 - inverse_pca_loss: 486687.3125 - val_loss: 393744.7188 - val_classical_outs_loss: 14.4613 - val_inverse_pca_loss: 393730.2500 - lr: 9.9504e-04\n",
      "Epoch 84/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 468811.3750 - classical_outs_loss: 14.6329 - inverse_pca_loss: 468796.6562 - val_loss: 430969.1875 - val_classical_outs_loss: 13.8188 - val_inverse_pca_loss: 430955.4062 - lr: 9.9498e-04\n",
      "Epoch 85/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 405405.6250 - classical_outs_loss: 13.9767 - inverse_pca_loss: 405391.7812 - val_loss: 865748.3125 - val_classical_outs_loss: 14.1722 - val_inverse_pca_loss: 865734.1875 - lr: 9.9492e-04\n",
      "Epoch 86/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 454094.8125 - classical_outs_loss: 13.9007 - inverse_pca_loss: 454080.8125 - val_loss: 549433.0000 - val_classical_outs_loss: 15.5618 - val_inverse_pca_loss: 549417.5000 - lr: 9.9486e-04\n",
      "Epoch 87/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 392715.7500 - classical_outs_loss: 14.9390 - inverse_pca_loss: 392700.8125 - val_loss: 561175.8125 - val_classical_outs_loss: 15.5497 - val_inverse_pca_loss: 561160.2500 - lr: 9.9480e-04\n",
      "Epoch 88/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 437957.8438 - classical_outs_loss: 13.3754 - inverse_pca_loss: 437944.4062 - val_loss: 416924.8125 - val_classical_outs_loss: 12.8885 - val_inverse_pca_loss: 416911.9375 - lr: 9.9474e-04\n",
      "Epoch 89/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 464816.0312 - classical_outs_loss: 13.9079 - inverse_pca_loss: 464802.0938 - val_loss: 425283.4688 - val_classical_outs_loss: 13.8412 - val_inverse_pca_loss: 425269.5938 - lr: 9.9468e-04\n",
      "Epoch 90/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 396700.8125 - classical_outs_loss: 13.6070 - inverse_pca_loss: 396687.1875 - val_loss: 262857.6250 - val_classical_outs_loss: 12.8520 - val_inverse_pca_loss: 262844.7500 - lr: 9.9462e-04\n",
      "Epoch 91/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 443433.8125 - classical_outs_loss: 13.5780 - inverse_pca_loss: 443420.2812 - val_loss: 508805.0000 - val_classical_outs_loss: 16.2809 - val_inverse_pca_loss: 508788.7188 - lr: 9.9456e-04\n",
      "Epoch 92/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 366556.1250 - classical_outs_loss: 12.9543 - inverse_pca_loss: 366543.1875 - val_loss: 347873.6562 - val_classical_outs_loss: 12.3005 - val_inverse_pca_loss: 347861.3438 - lr: 9.9450e-04\n",
      "Epoch 93/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 361865.6562 - classical_outs_loss: 13.7844 - inverse_pca_loss: 361851.8750 - val_loss: 306171.4688 - val_classical_outs_loss: 12.9185 - val_inverse_pca_loss: 306158.5625 - lr: 9.9444e-04\n",
      "Epoch 94/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 736412.9375 - classical_outs_loss: 15.6257 - inverse_pca_loss: 736397.1875 - val_loss: 264791.1250 - val_classical_outs_loss: 12.1635 - val_inverse_pca_loss: 264778.9688 - lr: 9.9438e-04\n",
      "Epoch 95/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 291930.6562 - classical_outs_loss: 12.2356 - inverse_pca_loss: 291918.3438 - val_loss: 437667.9375 - val_classical_outs_loss: 12.7501 - val_inverse_pca_loss: 437655.2188 - lr: 9.9432e-04\n",
      "Epoch 96/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 376680.4375 - classical_outs_loss: 12.4591 - inverse_pca_loss: 376668.0312 - val_loss: 377321.8438 - val_classical_outs_loss: 13.8184 - val_inverse_pca_loss: 377308.0312 - lr: 9.9426e-04\n",
      "Epoch 97/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 367064.0000 - classical_outs_loss: 12.6245 - inverse_pca_loss: 367051.4375 - val_loss: 360657.0938 - val_classical_outs_loss: 12.4331 - val_inverse_pca_loss: 360644.6562 - lr: 9.9420e-04\n",
      "Epoch 98/100000\n",
      "68/68 [==============================] - 1s 12ms/step - loss: 398754.9688 - classical_outs_loss: 13.1685 - inverse_pca_loss: 398741.7812 - val_loss: 239918.9844 - val_classical_outs_loss: 11.4539 - val_inverse_pca_loss: 239907.5000 - lr: 9.9414e-04\n",
      "Epoch 99/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 372153.5312 - classical_outs_loss: 12.2223 - inverse_pca_loss: 372141.2500 - val_loss: 284129.5312 - val_classical_outs_loss: 11.3366 - val_inverse_pca_loss: 284118.1562 - lr: 9.9408e-04\n",
      "Epoch 100/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 369356.8750 - classical_outs_loss: 12.4941 - inverse_pca_loss: 369344.4062 - val_loss: 623822.6875 - val_classical_outs_loss: 12.2339 - val_inverse_pca_loss: 623810.3750 - lr: 9.9402e-04\n",
      "Epoch 101/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 341976.8438 - classical_outs_loss: 12.1708 - inverse_pca_loss: 341964.6562 - val_loss: 242825.5781 - val_classical_outs_loss: 11.3224 - val_inverse_pca_loss: 242814.2656 - lr: 9.9396e-04\n",
      "Epoch 102/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 352833.5938 - classical_outs_loss: 12.2155 - inverse_pca_loss: 352821.4688 - val_loss: 342040.9375 - val_classical_outs_loss: 11.5632 - val_inverse_pca_loss: 342029.3438 - lr: 9.9390e-04\n",
      "Epoch 103/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 325621.5312 - classical_outs_loss: 12.2288 - inverse_pca_loss: 325609.3125 - val_loss: 271529.5312 - val_classical_outs_loss: 12.3755 - val_inverse_pca_loss: 271517.1875 - lr: 9.9384e-04\n",
      "Epoch 104/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 341111.4375 - classical_outs_loss: 11.8197 - inverse_pca_loss: 341099.6250 - val_loss: 322127.9375 - val_classical_outs_loss: 11.8971 - val_inverse_pca_loss: 322116.0312 - lr: 9.9378e-04\n",
      "Epoch 105/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 342124.3438 - classical_outs_loss: 11.9440 - inverse_pca_loss: 342112.4062 - val_loss: 680671.8125 - val_classical_outs_loss: 17.1072 - val_inverse_pca_loss: 680654.6875 - lr: 9.9372e-04\n",
      "Epoch 106/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 333963.2188 - classical_outs_loss: 12.1072 - inverse_pca_loss: 333951.0938 - val_loss: 277124.0938 - val_classical_outs_loss: 11.1020 - val_inverse_pca_loss: 277112.9688 - lr: 9.9366e-04\n",
      "Epoch 107/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 323325.9688 - classical_outs_loss: 11.4479 - inverse_pca_loss: 323314.5625 - val_loss: 267601.0625 - val_classical_outs_loss: 16.8000 - val_inverse_pca_loss: 267584.2812 - lr: 9.9360e-04\n",
      "Epoch 108/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 334119.7500 - classical_outs_loss: 11.5194 - inverse_pca_loss: 334108.1875 - val_loss: 408643.8125 - val_classical_outs_loss: 14.2491 - val_inverse_pca_loss: 408629.5625 - lr: 9.9354e-04\n",
      "Epoch 109/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 333667.9375 - classical_outs_loss: 11.8220 - inverse_pca_loss: 333656.0625 - val_loss: 398288.8438 - val_classical_outs_loss: 10.9694 - val_inverse_pca_loss: 398277.8438 - lr: 9.9349e-04\n",
      "Epoch 110/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 316640.9375 - classical_outs_loss: 11.2382 - inverse_pca_loss: 316629.7188 - val_loss: 599125.8125 - val_classical_outs_loss: 11.3743 - val_inverse_pca_loss: 599114.4375 - lr: 9.9343e-04\n",
      "Epoch 111/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 294386.2188 - classical_outs_loss: 11.8521 - inverse_pca_loss: 294374.3750 - val_loss: 1401114.1250 - val_classical_outs_loss: 12.6529 - val_inverse_pca_loss: 1401101.6250 - lr: 9.9337e-04\n",
      "Epoch 112/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 724392.1250 - classical_outs_loss: 15.4605 - inverse_pca_loss: 724376.3125 - val_loss: 261693.4062 - val_classical_outs_loss: 10.3868 - val_inverse_pca_loss: 261683.0156 - lr: 9.9331e-04\n",
      "Epoch 113/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 227294.7812 - classical_outs_loss: 10.4676 - inverse_pca_loss: 227284.3281 - val_loss: 223280.8906 - val_classical_outs_loss: 11.3693 - val_inverse_pca_loss: 223269.5156 - lr: 9.9325e-04\n",
      "Epoch 114/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 259584.8125 - classical_outs_loss: 11.8646 - inverse_pca_loss: 259572.9531 - val_loss: 203089.7031 - val_classical_outs_loss: 10.3220 - val_inverse_pca_loss: 203079.4062 - lr: 9.9319e-04\n",
      "Epoch 115/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 301732.1875 - classical_outs_loss: 11.1427 - inverse_pca_loss: 301721.0625 - val_loss: 212504.4062 - val_classical_outs_loss: 10.4327 - val_inverse_pca_loss: 212493.9844 - lr: 9.9313e-04\n",
      "Epoch 116/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 266417.6875 - classical_outs_loss: 11.4251 - inverse_pca_loss: 266406.2188 - val_loss: 299108.0938 - val_classical_outs_loss: 11.1651 - val_inverse_pca_loss: 299096.9375 - lr: 9.9307e-04\n",
      "Epoch 117/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 274389.5625 - classical_outs_loss: 11.3138 - inverse_pca_loss: 274378.2812 - val_loss: 342897.5000 - val_classical_outs_loss: 10.5773 - val_inverse_pca_loss: 342886.9375 - lr: 9.9301e-04\n",
      "Epoch 118/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 298027.5312 - classical_outs_loss: 10.9309 - inverse_pca_loss: 298016.6562 - val_loss: 369547.5938 - val_classical_outs_loss: 10.6388 - val_inverse_pca_loss: 369536.9688 - lr: 9.9295e-04\n",
      "Epoch 119/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 267816.1250 - classical_outs_loss: 11.0917 - inverse_pca_loss: 267805.0625 - val_loss: 201117.3594 - val_classical_outs_loss: 11.1904 - val_inverse_pca_loss: 201106.1562 - lr: 9.9289e-04\n",
      "Epoch 120/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 316010.8125 - classical_outs_loss: 10.9138 - inverse_pca_loss: 315999.9688 - val_loss: 291922.9375 - val_classical_outs_loss: 10.7796 - val_inverse_pca_loss: 291912.1250 - lr: 9.9283e-04\n",
      "Epoch 121/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 243207.6719 - classical_outs_loss: 10.3543 - inverse_pca_loss: 243197.3594 - val_loss: 401190.0000 - val_classical_outs_loss: 10.0724 - val_inverse_pca_loss: 401179.9062 - lr: 9.9277e-04\n",
      "Epoch 122/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 266726.5938 - classical_outs_loss: 10.8544 - inverse_pca_loss: 266715.7500 - val_loss: 235802.0781 - val_classical_outs_loss: 10.2638 - val_inverse_pca_loss: 235791.7969 - lr: 9.9271e-04\n",
      "Epoch 123/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 249821.4688 - classical_outs_loss: 10.6414 - inverse_pca_loss: 249810.8750 - val_loss: 168254.1094 - val_classical_outs_loss: 10.1302 - val_inverse_pca_loss: 168243.9844 - lr: 9.9265e-04\n",
      "Epoch 124/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 295423.5000 - classical_outs_loss: 10.7081 - inverse_pca_loss: 295412.8125 - val_loss: 211630.9844 - val_classical_outs_loss: 10.0793 - val_inverse_pca_loss: 211620.9062 - lr: 9.9259e-04\n",
      "Epoch 125/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 290531.4062 - classical_outs_loss: 11.0926 - inverse_pca_loss: 290520.2188 - val_loss: 223123.1562 - val_classical_outs_loss: 11.8378 - val_inverse_pca_loss: 223111.3281 - lr: 9.9253e-04\n",
      "Epoch 126/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 227523.7812 - classical_outs_loss: 10.6704 - inverse_pca_loss: 227513.1562 - val_loss: 241903.9688 - val_classical_outs_loss: 9.8666 - val_inverse_pca_loss: 241894.0938 - lr: 9.9247e-04\n",
      "Epoch 127/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 238581.0469 - classical_outs_loss: 10.6845 - inverse_pca_loss: 238570.3438 - val_loss: 169144.9844 - val_classical_outs_loss: 9.6635 - val_inverse_pca_loss: 169135.3125 - lr: 9.9241e-04\n",
      "Epoch 128/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 269324.1562 - classical_outs_loss: 9.8979 - inverse_pca_loss: 269314.2500 - val_loss: 235518.7969 - val_classical_outs_loss: 10.0141 - val_inverse_pca_loss: 235508.7812 - lr: 9.9235e-04\n",
      "Epoch 129/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 227937.8281 - classical_outs_loss: 10.2575 - inverse_pca_loss: 227927.6094 - val_loss: 778725.8125 - val_classical_outs_loss: 10.8327 - val_inverse_pca_loss: 778715.0000 - lr: 9.9229e-04\n",
      "Epoch 130/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 239055.7344 - classical_outs_loss: 10.4050 - inverse_pca_loss: 239045.3438 - val_loss: 115193.0000 - val_classical_outs_loss: 10.9034 - val_inverse_pca_loss: 115182.1172 - lr: 9.9224e-04\n",
      "Epoch 131/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 235128.0781 - classical_outs_loss: 10.6404 - inverse_pca_loss: 235117.4062 - val_loss: 412709.6250 - val_classical_outs_loss: 10.0887 - val_inverse_pca_loss: 412699.5625 - lr: 9.9218e-04\n",
      "Epoch 132/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 246918.5156 - classical_outs_loss: 9.8211 - inverse_pca_loss: 246908.6719 - val_loss: 242082.0156 - val_classical_outs_loss: 10.0063 - val_inverse_pca_loss: 242072.0312 - lr: 9.9212e-04\n",
      "Epoch 133/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 216439.5000 - classical_outs_loss: 10.6488 - inverse_pca_loss: 216428.8594 - val_loss: 169750.5781 - val_classical_outs_loss: 10.0400 - val_inverse_pca_loss: 169740.5312 - lr: 9.9206e-04\n",
      "Epoch 134/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 224202.1562 - classical_outs_loss: 9.6112 - inverse_pca_loss: 224192.5469 - val_loss: 280968.3750 - val_classical_outs_loss: 9.3129 - val_inverse_pca_loss: 280959.0625 - lr: 9.9200e-04\n",
      "Epoch 135/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 231491.9375 - classical_outs_loss: 10.4514 - inverse_pca_loss: 231481.5156 - val_loss: 163843.1719 - val_classical_outs_loss: 10.8364 - val_inverse_pca_loss: 163832.3594 - lr: 9.9194e-04\n",
      "Epoch 136/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 225502.0781 - classical_outs_loss: 10.0262 - inverse_pca_loss: 225492.0625 - val_loss: 193101.4375 - val_classical_outs_loss: 9.1917 - val_inverse_pca_loss: 193092.2500 - lr: 9.9188e-04\n",
      "Epoch 137/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 212746.3750 - classical_outs_loss: 9.9296 - inverse_pca_loss: 212736.4062 - val_loss: 128200.9922 - val_classical_outs_loss: 9.8587 - val_inverse_pca_loss: 128191.1328 - lr: 9.9182e-04\n",
      "Epoch 138/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 235849.3594 - classical_outs_loss: 9.7891 - inverse_pca_loss: 235839.6250 - val_loss: 182426.4062 - val_classical_outs_loss: 9.3262 - val_inverse_pca_loss: 182417.0781 - lr: 9.9176e-04\n",
      "Epoch 139/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 198279.2031 - classical_outs_loss: 10.0126 - inverse_pca_loss: 198269.2031 - val_loss: 134607.8906 - val_classical_outs_loss: 9.2292 - val_inverse_pca_loss: 134598.6562 - lr: 9.9170e-04\n",
      "Epoch 140/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 204045.4531 - classical_outs_loss: 9.8659 - inverse_pca_loss: 204035.6250 - val_loss: 279056.1875 - val_classical_outs_loss: 9.1228 - val_inverse_pca_loss: 279047.0312 - lr: 9.9164e-04\n",
      "Epoch 141/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 217575.4531 - classical_outs_loss: 9.8655 - inverse_pca_loss: 217565.5938 - val_loss: 152528.2656 - val_classical_outs_loss: 9.4964 - val_inverse_pca_loss: 152518.7656 - lr: 9.9158e-04\n",
      "Epoch 142/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 214839.1406 - classical_outs_loss: 9.8617 - inverse_pca_loss: 214829.2656 - val_loss: 280987.9062 - val_classical_outs_loss: 9.4222 - val_inverse_pca_loss: 280978.4688 - lr: 9.9152e-04\n",
      "Epoch 143/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 209264.7969 - classical_outs_loss: 9.9538 - inverse_pca_loss: 209254.8125 - val_loss: 296197.0000 - val_classical_outs_loss: 11.0326 - val_inverse_pca_loss: 296185.9375 - lr: 9.9146e-04\n",
      "Epoch 144/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 217533.6094 - classical_outs_loss: 9.7445 - inverse_pca_loss: 217523.8594 - val_loss: 133080.5000 - val_classical_outs_loss: 8.6702 - val_inverse_pca_loss: 133071.8125 - lr: 9.9140e-04\n",
      "Epoch 145/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 193371.7656 - classical_outs_loss: 9.4198 - inverse_pca_loss: 193362.3281 - val_loss: 139184.2344 - val_classical_outs_loss: 8.8462 - val_inverse_pca_loss: 139175.3750 - lr: 9.9134e-04\n",
      "Epoch 146/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 210670.8125 - classical_outs_loss: 9.6858 - inverse_pca_loss: 210661.0938 - val_loss: 119459.1094 - val_classical_outs_loss: 8.8875 - val_inverse_pca_loss: 119450.2188 - lr: 9.9128e-04\n",
      "Epoch 147/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 195430.1406 - classical_outs_loss: 9.6127 - inverse_pca_loss: 195420.4688 - val_loss: 118568.7109 - val_classical_outs_loss: 12.2009 - val_inverse_pca_loss: 118556.5078 - lr: 9.9122e-04\n",
      "Epoch 148/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 195333.8750 - classical_outs_loss: 9.4839 - inverse_pca_loss: 195324.4375 - val_loss: 302831.7188 - val_classical_outs_loss: 9.3561 - val_inverse_pca_loss: 302822.3750 - lr: 9.9116e-04\n",
      "Epoch 149/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 202580.7812 - classical_outs_loss: 9.3034 - inverse_pca_loss: 202571.5469 - val_loss: 141728.2344 - val_classical_outs_loss: 8.5182 - val_inverse_pca_loss: 141719.7031 - lr: 9.9110e-04\n",
      "Epoch 150/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 190303.2344 - classical_outs_loss: 10.0122 - inverse_pca_loss: 190293.2188 - val_loss: 100442.4297 - val_classical_outs_loss: 9.2770 - val_inverse_pca_loss: 100433.1406 - lr: 9.9105e-04\n",
      "Epoch 151/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 205505.1719 - classical_outs_loss: 9.3158 - inverse_pca_loss: 205495.8906 - val_loss: 85558.1562 - val_classical_outs_loss: 8.5319 - val_inverse_pca_loss: 85549.6250 - lr: 9.9099e-04\n",
      "Epoch 152/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 223938.7188 - classical_outs_loss: 9.1013 - inverse_pca_loss: 223929.5938 - val_loss: 82972.1328 - val_classical_outs_loss: 8.4431 - val_inverse_pca_loss: 82963.6875 - lr: 9.9093e-04\n",
      "Epoch 153/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 209902.4219 - classical_outs_loss: 9.6966 - inverse_pca_loss: 209892.7344 - val_loss: 74352.3125 - val_classical_outs_loss: 8.2352 - val_inverse_pca_loss: 74344.0781 - lr: 9.9087e-04\n",
      "Epoch 154/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 204404.4688 - classical_outs_loss: 9.1435 - inverse_pca_loss: 204395.3281 - val_loss: 183329.1875 - val_classical_outs_loss: 10.0487 - val_inverse_pca_loss: 183319.1562 - lr: 9.9081e-04\n",
      "Epoch 155/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 192238.6719 - classical_outs_loss: 9.3175 - inverse_pca_loss: 192229.3281 - val_loss: 157818.6250 - val_classical_outs_loss: 8.7765 - val_inverse_pca_loss: 157809.8438 - lr: 9.9075e-04\n",
      "Epoch 156/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 183015.7656 - classical_outs_loss: 9.1558 - inverse_pca_loss: 183006.6250 - val_loss: 174614.0000 - val_classical_outs_loss: 10.4992 - val_inverse_pca_loss: 174603.5000 - lr: 9.9069e-04\n",
      "Epoch 157/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 162238.5469 - classical_outs_loss: 8.8038 - inverse_pca_loss: 162229.7500 - val_loss: 228143.8281 - val_classical_outs_loss: 8.7598 - val_inverse_pca_loss: 228135.0781 - lr: 9.9063e-04\n",
      "Epoch 158/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 185895.8125 - classical_outs_loss: 9.4636 - inverse_pca_loss: 185886.3438 - val_loss: 164408.4531 - val_classical_outs_loss: 8.5095 - val_inverse_pca_loss: 164399.9375 - lr: 9.9057e-04\n",
      "Epoch 159/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 179848.0938 - classical_outs_loss: 8.9171 - inverse_pca_loss: 179839.1406 - val_loss: 78417.4766 - val_classical_outs_loss: 8.1189 - val_inverse_pca_loss: 78409.3516 - lr: 9.9051e-04\n",
      "Epoch 160/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 249142.8281 - classical_outs_loss: 9.5537 - inverse_pca_loss: 249133.2969 - val_loss: 152684.0781 - val_classical_outs_loss: 10.0141 - val_inverse_pca_loss: 152674.0625 - lr: 9.9045e-04\n",
      "Epoch 161/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 150256.9219 - classical_outs_loss: 8.5251 - inverse_pca_loss: 150248.4219 - val_loss: 296677.1250 - val_classical_outs_loss: 9.2973 - val_inverse_pca_loss: 296667.8125 - lr: 9.9039e-04\n",
      "Epoch 162/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 211477.3281 - classical_outs_loss: 8.9398 - inverse_pca_loss: 211468.4062 - val_loss: 320240.1250 - val_classical_outs_loss: 9.3693 - val_inverse_pca_loss: 320230.7500 - lr: 9.9033e-04\n",
      "Epoch 163/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 165362.5625 - classical_outs_loss: 9.7455 - inverse_pca_loss: 165352.8750 - val_loss: 88053.6172 - val_classical_outs_loss: 9.7331 - val_inverse_pca_loss: 88043.8906 - lr: 9.9027e-04\n",
      "Epoch 164/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 176522.6250 - classical_outs_loss: 8.5712 - inverse_pca_loss: 176514.0469 - val_loss: 119828.1875 - val_classical_outs_loss: 8.1356 - val_inverse_pca_loss: 119820.0547 - lr: 9.9021e-04\n",
      "Epoch 165/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 207963.1250 - classical_outs_loss: 8.8607 - inverse_pca_loss: 207954.2656 - val_loss: 152374.7188 - val_classical_outs_loss: 10.1048 - val_inverse_pca_loss: 152364.5938 - lr: 9.9015e-04\n",
      "Epoch 166/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 193534.2969 - classical_outs_loss: 8.9137 - inverse_pca_loss: 193525.3281 - val_loss: 97680.0234 - val_classical_outs_loss: 8.1329 - val_inverse_pca_loss: 97671.9062 - lr: 9.9010e-04\n",
      "Epoch 167/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 187242.4688 - classical_outs_loss: 9.0801 - inverse_pca_loss: 187233.3906 - val_loss: 188188.0781 - val_classical_outs_loss: 8.4704 - val_inverse_pca_loss: 188179.6094 - lr: 9.9004e-04\n",
      "Epoch 168/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 168140.2656 - classical_outs_loss: 8.2607 - inverse_pca_loss: 168132.0312 - val_loss: 172493.9688 - val_classical_outs_loss: 8.3522 - val_inverse_pca_loss: 172485.6250 - lr: 9.8998e-04\n",
      "Epoch 169/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 151377.4375 - classical_outs_loss: 9.0543 - inverse_pca_loss: 151368.3906 - val_loss: 268175.9375 - val_classical_outs_loss: 9.0232 - val_inverse_pca_loss: 268166.9062 - lr: 9.8992e-04\n",
      "Epoch 170/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 168663.2344 - classical_outs_loss: 9.0618 - inverse_pca_loss: 168654.1875 - val_loss: 133403.2812 - val_classical_outs_loss: 8.1208 - val_inverse_pca_loss: 133395.1875 - lr: 9.8986e-04\n",
      "Epoch 171/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 161467.7812 - classical_outs_loss: 8.4744 - inverse_pca_loss: 161459.3125 - val_loss: 85567.3906 - val_classical_outs_loss: 8.3937 - val_inverse_pca_loss: 85559.0000 - lr: 9.8980e-04\n",
      "Epoch 172/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 183694.4688 - classical_outs_loss: 8.5469 - inverse_pca_loss: 183685.9375 - val_loss: 112228.4375 - val_classical_outs_loss: 8.0647 - val_inverse_pca_loss: 112220.3672 - lr: 9.8974e-04\n",
      "Epoch 173/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 172669.2031 - classical_outs_loss: 8.9900 - inverse_pca_loss: 172660.2031 - val_loss: 146534.0312 - val_classical_outs_loss: 8.9795 - val_inverse_pca_loss: 146525.0625 - lr: 9.8968e-04\n",
      "Epoch 174/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 148429.7656 - classical_outs_loss: 8.0845 - inverse_pca_loss: 148421.6719 - val_loss: 84146.2500 - val_classical_outs_loss: 8.0137 - val_inverse_pca_loss: 84138.2422 - lr: 9.8962e-04\n",
      "Epoch 175/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 175331.7969 - classical_outs_loss: 9.4045 - inverse_pca_loss: 175322.4688 - val_loss: 148474.4844 - val_classical_outs_loss: 7.8948 - val_inverse_pca_loss: 148466.5781 - lr: 9.8956e-04\n",
      "Epoch 176/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 157008.2344 - classical_outs_loss: 8.0603 - inverse_pca_loss: 157000.1719 - val_loss: 139628.5000 - val_classical_outs_loss: 7.9233 - val_inverse_pca_loss: 139620.5781 - lr: 9.8950e-04\n",
      "Epoch 177/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 212551.7188 - classical_outs_loss: 8.5847 - inverse_pca_loss: 212543.1562 - val_loss: 343186.1875 - val_classical_outs_loss: 7.9274 - val_inverse_pca_loss: 343178.2500 - lr: 9.8944e-04\n",
      "Epoch 178/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 164736.2500 - classical_outs_loss: 8.5501 - inverse_pca_loss: 164727.6562 - val_loss: 78634.7656 - val_classical_outs_loss: 9.3313 - val_inverse_pca_loss: 78625.4453 - lr: 9.8938e-04\n",
      "Epoch 179/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 175058.1250 - classical_outs_loss: 9.1000 - inverse_pca_loss: 175049.0000 - val_loss: 111426.3438 - val_classical_outs_loss: 8.2516 - val_inverse_pca_loss: 111418.1016 - lr: 9.8932e-04\n",
      "Epoch 180/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 156041.7969 - classical_outs_loss: 7.9643 - inverse_pca_loss: 156033.8281 - val_loss: 144354.3750 - val_classical_outs_loss: 9.2987 - val_inverse_pca_loss: 144345.0625 - lr: 9.8926e-04\n",
      "Epoch 181/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 146537.5938 - classical_outs_loss: 8.5306 - inverse_pca_loss: 146529.0781 - val_loss: 331491.9375 - val_classical_outs_loss: 8.5921 - val_inverse_pca_loss: 331483.3438 - lr: 9.8920e-04\n",
      "Epoch 182/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 149075.5469 - classical_outs_loss: 8.4977 - inverse_pca_loss: 149067.0156 - val_loss: 292588.4062 - val_classical_outs_loss: 8.6853 - val_inverse_pca_loss: 292579.7500 - lr: 9.8915e-04\n",
      "Epoch 183/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 169032.2188 - classical_outs_loss: 8.5892 - inverse_pca_loss: 169023.6406 - val_loss: 156658.1094 - val_classical_outs_loss: 9.0819 - val_inverse_pca_loss: 156649.0312 - lr: 9.8909e-04\n",
      "Epoch 184/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 151365.7656 - classical_outs_loss: 7.9862 - inverse_pca_loss: 151357.7188 - val_loss: 235137.3906 - val_classical_outs_loss: 8.0296 - val_inverse_pca_loss: 235129.3750 - lr: 9.8903e-04\n",
      "Epoch 185/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 170756.9688 - classical_outs_loss: 7.9614 - inverse_pca_loss: 170748.9844 - val_loss: 119597.8828 - val_classical_outs_loss: 7.6092 - val_inverse_pca_loss: 119590.2734 - lr: 9.8897e-04\n",
      "Epoch 186/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 172747.9844 - classical_outs_loss: 8.4888 - inverse_pca_loss: 172739.4375 - val_loss: 193872.0938 - val_classical_outs_loss: 9.0910 - val_inverse_pca_loss: 193863.0000 - lr: 9.8891e-04\n",
      "Epoch 187/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 159276.2188 - classical_outs_loss: 8.6931 - inverse_pca_loss: 159267.5469 - val_loss: 75146.9531 - val_classical_outs_loss: 7.9813 - val_inverse_pca_loss: 75138.9766 - lr: 9.8885e-04\n",
      "Epoch 188/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 150342.5312 - classical_outs_loss: 7.9228 - inverse_pca_loss: 150334.6094 - val_loss: 114063.8984 - val_classical_outs_loss: 7.6693 - val_inverse_pca_loss: 114056.2266 - lr: 9.8879e-04\n",
      "Epoch 189/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 157666.8906 - classical_outs_loss: 8.3178 - inverse_pca_loss: 157658.6250 - val_loss: 116012.2344 - val_classical_outs_loss: 8.6865 - val_inverse_pca_loss: 116003.5625 - lr: 9.8873e-04\n",
      "Epoch 190/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 129220.6562 - classical_outs_loss: 7.7985 - inverse_pca_loss: 129212.8984 - val_loss: 163039.8281 - val_classical_outs_loss: 7.3330 - val_inverse_pca_loss: 163032.5156 - lr: 9.8867e-04\n",
      "Epoch 191/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 178664.0469 - classical_outs_loss: 8.8857 - inverse_pca_loss: 178655.1719 - val_loss: 112107.5703 - val_classical_outs_loss: 7.5238 - val_inverse_pca_loss: 112100.0391 - lr: 9.8861e-04\n",
      "Epoch 192/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 141052.5938 - classical_outs_loss: 7.6291 - inverse_pca_loss: 141044.9844 - val_loss: 141585.4062 - val_classical_outs_loss: 9.6817 - val_inverse_pca_loss: 141575.7188 - lr: 9.8855e-04\n",
      "Epoch 193/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 199111.9062 - classical_outs_loss: 8.4212 - inverse_pca_loss: 199103.5312 - val_loss: 219984.9844 - val_classical_outs_loss: 8.2631 - val_inverse_pca_loss: 219976.7344 - lr: 9.8849e-04\n",
      "Epoch 194/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 127408.8516 - classical_outs_loss: 7.9199 - inverse_pca_loss: 127400.9141 - val_loss: 140709.6875 - val_classical_outs_loss: 10.0415 - val_inverse_pca_loss: 140699.6562 - lr: 9.8843e-04\n",
      "Epoch 195/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 142793.7969 - classical_outs_loss: 8.2120 - inverse_pca_loss: 142785.5938 - val_loss: 106226.2266 - val_classical_outs_loss: 7.5697 - val_inverse_pca_loss: 106218.6641 - lr: 9.8838e-04\n",
      "Epoch 196/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 137329.4688 - classical_outs_loss: 7.8653 - inverse_pca_loss: 137321.6406 - val_loss: 685491.7500 - val_classical_outs_loss: 8.7759 - val_inverse_pca_loss: 685482.9375 - lr: 9.8832e-04\n",
      "Epoch 197/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 175276.8750 - classical_outs_loss: 8.2403 - inverse_pca_loss: 175268.6875 - val_loss: 64293.7773 - val_classical_outs_loss: 8.8193 - val_inverse_pca_loss: 64284.9570 - lr: 9.8826e-04\n",
      "Epoch 198/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 164689.4219 - classical_outs_loss: 8.3304 - inverse_pca_loss: 164681.0938 - val_loss: 109374.6250 - val_classical_outs_loss: 7.3063 - val_inverse_pca_loss: 109367.3203 - lr: 9.8820e-04\n",
      "Epoch 199/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 126604.7500 - classical_outs_loss: 7.7389 - inverse_pca_loss: 126597.0000 - val_loss: 90063.3359 - val_classical_outs_loss: 7.1051 - val_inverse_pca_loss: 90056.2266 - lr: 9.8814e-04\n",
      "Epoch 200/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 160464.5938 - classical_outs_loss: 7.9051 - inverse_pca_loss: 160456.6875 - val_loss: 97390.3438 - val_classical_outs_loss: 7.3486 - val_inverse_pca_loss: 97382.9922 - lr: 9.8808e-04\n",
      "Epoch 201/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 129875.7500 - classical_outs_loss: 8.3278 - inverse_pca_loss: 129867.4375 - val_loss: 243290.5781 - val_classical_outs_loss: 7.8223 - val_inverse_pca_loss: 243282.7500 - lr: 9.8802e-04\n",
      "Epoch 202/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 155679.3281 - classical_outs_loss: 7.4558 - inverse_pca_loss: 155671.9062 - val_loss: 249242.2344 - val_classical_outs_loss: 8.1372 - val_inverse_pca_loss: 249234.0781 - lr: 9.8796e-04\n",
      "Epoch 203/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 143901.3281 - classical_outs_loss: 7.6326 - inverse_pca_loss: 143893.7031 - val_loss: 147558.2188 - val_classical_outs_loss: 7.6374 - val_inverse_pca_loss: 147550.5938 - lr: 9.8790e-04\n",
      "Epoch 204/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 123078.2031 - classical_outs_loss: 8.0907 - inverse_pca_loss: 123070.0781 - val_loss: 91742.4141 - val_classical_outs_loss: 7.3474 - val_inverse_pca_loss: 91735.0703 - lr: 9.8784e-04\n",
      "Epoch 205/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 142727.6094 - classical_outs_loss: 7.7950 - inverse_pca_loss: 142719.8125 - val_loss: 77969.2422 - val_classical_outs_loss: 7.4997 - val_inverse_pca_loss: 77961.7422 - lr: 9.8778e-04\n",
      "Epoch 206/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 161367.7344 - classical_outs_loss: 8.2725 - inverse_pca_loss: 161359.4531 - val_loss: 154300.0312 - val_classical_outs_loss: 7.5128 - val_inverse_pca_loss: 154292.5312 - lr: 9.8772e-04\n",
      "Epoch 207/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 148156.9375 - classical_outs_loss: 7.5302 - inverse_pca_loss: 148149.4219 - val_loss: 225644.9375 - val_classical_outs_loss: 7.2558 - val_inverse_pca_loss: 225637.7031 - lr: 9.8766e-04\n",
      "Epoch 208/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 147196.2344 - classical_outs_loss: 8.0831 - inverse_pca_loss: 147188.1406 - val_loss: 113499.4453 - val_classical_outs_loss: 6.9023 - val_inverse_pca_loss: 113492.5547 - lr: 9.8760e-04\n",
      "Epoch 209/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 135766.1094 - classical_outs_loss: 7.5471 - inverse_pca_loss: 135758.5781 - val_loss: 61963.8789 - val_classical_outs_loss: 7.1830 - val_inverse_pca_loss: 61956.6953 - lr: 9.8755e-04\n",
      "Epoch 210/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 161966.7188 - classical_outs_loss: 7.9320 - inverse_pca_loss: 161958.7969 - val_loss: 175123.7500 - val_classical_outs_loss: 9.7134 - val_inverse_pca_loss: 175114.0312 - lr: 9.8749e-04\n",
      "Epoch 211/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 139028.5156 - classical_outs_loss: 7.8162 - inverse_pca_loss: 139020.7031 - val_loss: 115593.3281 - val_classical_outs_loss: 8.3893 - val_inverse_pca_loss: 115584.9375 - lr: 9.8743e-04\n",
      "Epoch 212/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 127925.1406 - classical_outs_loss: 7.7632 - inverse_pca_loss: 127917.3906 - val_loss: 126565.6797 - val_classical_outs_loss: 7.5390 - val_inverse_pca_loss: 126558.1562 - lr: 9.8737e-04\n",
      "Epoch 213/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 152063.2969 - classical_outs_loss: 7.5961 - inverse_pca_loss: 152055.7188 - val_loss: 58557.0664 - val_classical_outs_loss: 7.3418 - val_inverse_pca_loss: 58549.7305 - lr: 9.8731e-04\n",
      "Epoch 214/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 125791.4531 - classical_outs_loss: 7.6109 - inverse_pca_loss: 125783.8438 - val_loss: 150032.7344 - val_classical_outs_loss: 10.2618 - val_inverse_pca_loss: 150022.4844 - lr: 9.8725e-04\n",
      "Epoch 215/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 135048.4375 - classical_outs_loss: 7.3895 - inverse_pca_loss: 135041.0625 - val_loss: 62921.2695 - val_classical_outs_loss: 7.8163 - val_inverse_pca_loss: 62913.4492 - lr: 9.8719e-04\n",
      "Epoch 216/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 123073.1953 - classical_outs_loss: 7.7944 - inverse_pca_loss: 123065.4219 - val_loss: 87999.1016 - val_classical_outs_loss: 7.5269 - val_inverse_pca_loss: 87991.5703 - lr: 9.8713e-04\n",
      "Epoch 217/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 199936.3594 - classical_outs_loss: 8.0982 - inverse_pca_loss: 199928.2500 - val_loss: 145195.7031 - val_classical_outs_loss: 7.0838 - val_inverse_pca_loss: 145188.6094 - lr: 9.8707e-04\n",
      "Epoch 218/100000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 142569.0469 - classical_outs_loss: 7.4667 - inverse_pca_loss: 142561.6250 - val_loss: 149357.3906 - val_classical_outs_loss: 8.5901 - val_inverse_pca_loss: 149348.7812 - lr: 9.8701e-04\n",
      "Epoch 219/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 109304.5156 - classical_outs_loss: 7.4609 - inverse_pca_loss: 109297.0391 - val_loss: 66263.7031 - val_classical_outs_loss: 7.0956 - val_inverse_pca_loss: 66256.6094 - lr: 9.8695e-04\n",
      "Epoch 220/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 122585.8828 - classical_outs_loss: 7.5240 - inverse_pca_loss: 122578.3359 - val_loss: 120088.4688 - val_classical_outs_loss: 6.7249 - val_inverse_pca_loss: 120081.7422 - lr: 9.8689e-04\n",
      "Epoch 221/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 130207.7969 - classical_outs_loss: 7.2897 - inverse_pca_loss: 130200.5078 - val_loss: 234115.4844 - val_classical_outs_loss: 8.1991 - val_inverse_pca_loss: 234107.2812 - lr: 9.8684e-04\n",
      "Epoch 222/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 149591.6406 - classical_outs_loss: 8.0791 - inverse_pca_loss: 149583.5625 - val_loss: 128384.3203 - val_classical_outs_loss: 7.8798 - val_inverse_pca_loss: 128376.4375 - lr: 9.8678e-04\n",
      "Epoch 223/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 122277.3828 - classical_outs_loss: 7.2768 - inverse_pca_loss: 122270.1406 - val_loss: 137909.5000 - val_classical_outs_loss: 6.6783 - val_inverse_pca_loss: 137902.7969 - lr: 9.8672e-04\n",
      "Epoch 224/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 119512.7734 - classical_outs_loss: 7.3113 - inverse_pca_loss: 119505.4766 - val_loss: 92083.4062 - val_classical_outs_loss: 6.5155 - val_inverse_pca_loss: 92076.8906 - lr: 9.8666e-04\n",
      "Epoch 225/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 115420.2891 - classical_outs_loss: 7.7652 - inverse_pca_loss: 115412.5000 - val_loss: 121666.0234 - val_classical_outs_loss: 7.5604 - val_inverse_pca_loss: 121658.4688 - lr: 9.8660e-04\n",
      "Epoch 226/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 146305.0000 - classical_outs_loss: 7.1312 - inverse_pca_loss: 146297.8594 - val_loss: 97930.2500 - val_classical_outs_loss: 6.7941 - val_inverse_pca_loss: 97923.4453 - lr: 9.8654e-04\n",
      "Epoch 227/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 138358.9688 - classical_outs_loss: 7.6017 - inverse_pca_loss: 138351.3594 - val_loss: 221442.4844 - val_classical_outs_loss: 10.2880 - val_inverse_pca_loss: 221432.2031 - lr: 9.8648e-04\n",
      "Epoch 228/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 124926.3750 - classical_outs_loss: 7.3297 - inverse_pca_loss: 124919.0391 - val_loss: 387398.9062 - val_classical_outs_loss: 7.6587 - val_inverse_pca_loss: 387391.2500 - lr: 9.8642e-04\n",
      "Epoch 229/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 148049.8594 - classical_outs_loss: 7.2472 - inverse_pca_loss: 148042.6250 - val_loss: 88376.4688 - val_classical_outs_loss: 6.4460 - val_inverse_pca_loss: 88370.0234 - lr: 9.8636e-04\n",
      "Epoch 230/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 137176.8125 - classical_outs_loss: 7.5225 - inverse_pca_loss: 137169.2812 - val_loss: 98318.1719 - val_classical_outs_loss: 7.4262 - val_inverse_pca_loss: 98310.7422 - lr: 9.8630e-04\n",
      "Epoch 231/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 113069.0156 - classical_outs_loss: 7.3899 - inverse_pca_loss: 113061.6328 - val_loss: 48400.0117 - val_classical_outs_loss: 7.9096 - val_inverse_pca_loss: 48392.0977 - lr: 9.8624e-04\n",
      "Epoch 232/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 127944.9141 - classical_outs_loss: 7.4070 - inverse_pca_loss: 127937.5391 - val_loss: 189631.2969 - val_classical_outs_loss: 7.7557 - val_inverse_pca_loss: 189623.5469 - lr: 9.8618e-04\n",
      "Epoch 233/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 126482.8516 - classical_outs_loss: 6.9226 - inverse_pca_loss: 126475.9375 - val_loss: 184252.5625 - val_classical_outs_loss: 9.1117 - val_inverse_pca_loss: 184243.4219 - lr: 9.8613e-04\n",
      "Epoch 234/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 117169.3594 - classical_outs_loss: 7.8545 - inverse_pca_loss: 117161.4922 - val_loss: 76526.1484 - val_classical_outs_loss: 6.8663 - val_inverse_pca_loss: 76519.2734 - lr: 9.8607e-04\n",
      "Epoch 235/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 125791.9453 - classical_outs_loss: 7.0533 - inverse_pca_loss: 125784.8828 - val_loss: 76991.1953 - val_classical_outs_loss: 6.8180 - val_inverse_pca_loss: 76984.3750 - lr: 9.8601e-04\n",
      "Epoch 236/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 129277.1719 - classical_outs_loss: 7.1965 - inverse_pca_loss: 129269.9609 - val_loss: 112294.4844 - val_classical_outs_loss: 7.0304 - val_inverse_pca_loss: 112287.4531 - lr: 9.8595e-04\n",
      "Epoch 237/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 121827.2734 - classical_outs_loss: 7.1406 - inverse_pca_loss: 121820.1172 - val_loss: 61486.1758 - val_classical_outs_loss: 7.2907 - val_inverse_pca_loss: 61478.8867 - lr: 9.8589e-04\n",
      "Epoch 238/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 104302.0078 - classical_outs_loss: 7.2909 - inverse_pca_loss: 104294.7266 - val_loss: 281419.9688 - val_classical_outs_loss: 8.4059 - val_inverse_pca_loss: 281411.5625 - lr: 9.8583e-04\n",
      "Epoch 239/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 144287.6875 - classical_outs_loss: 7.1910 - inverse_pca_loss: 144280.5156 - val_loss: 83095.5156 - val_classical_outs_loss: 6.5077 - val_inverse_pca_loss: 83089.0000 - lr: 9.8577e-04\n",
      "Epoch 240/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 133952.0625 - classical_outs_loss: 7.1005 - inverse_pca_loss: 133944.9375 - val_loss: 69899.6328 - val_classical_outs_loss: 6.4304 - val_inverse_pca_loss: 69893.2031 - lr: 9.8571e-04\n",
      "Epoch 241/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 119096.2188 - classical_outs_loss: 7.4968 - inverse_pca_loss: 119088.7109 - val_loss: 126738.7734 - val_classical_outs_loss: 7.2839 - val_inverse_pca_loss: 126731.4844 - lr: 9.8565e-04\n",
      "Epoch 242/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 117255.9219 - classical_outs_loss: 6.7408 - inverse_pca_loss: 117249.1719 - val_loss: 120188.7812 - val_classical_outs_loss: 6.8664 - val_inverse_pca_loss: 120181.9141 - lr: 9.8559e-04\n",
      "Epoch 243/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 128394.0547 - classical_outs_loss: 7.8232 - inverse_pca_loss: 128386.2500 - val_loss: 310279.8125 - val_classical_outs_loss: 7.5724 - val_inverse_pca_loss: 310272.2500 - lr: 9.8553e-04\n",
      "Epoch 244/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 141109.0938 - classical_outs_loss: 6.9847 - inverse_pca_loss: 141102.1250 - val_loss: 80498.8438 - val_classical_outs_loss: 6.5745 - val_inverse_pca_loss: 80492.2734 - lr: 9.8548e-04\n",
      "Epoch 245/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 106791.6094 - classical_outs_loss: 6.9548 - inverse_pca_loss: 106784.6328 - val_loss: 73606.4297 - val_classical_outs_loss: 7.2357 - val_inverse_pca_loss: 73599.1953 - lr: 9.8542e-04\n",
      "Epoch 246/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 108598.8906 - classical_outs_loss: 7.1474 - inverse_pca_loss: 108591.7578 - val_loss: 90265.2578 - val_classical_outs_loss: 6.4425 - val_inverse_pca_loss: 90258.8125 - lr: 9.8536e-04\n",
      "Epoch 247/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 166322.0469 - classical_outs_loss: 6.9225 - inverse_pca_loss: 166315.1406 - val_loss: 66661.3594 - val_classical_outs_loss: 6.2308 - val_inverse_pca_loss: 66655.1250 - lr: 9.8530e-04\n",
      "Epoch 248/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 115728.3281 - classical_outs_loss: 7.1853 - inverse_pca_loss: 115721.1406 - val_loss: 112366.6953 - val_classical_outs_loss: 7.4683 - val_inverse_pca_loss: 112359.2344 - lr: 9.8524e-04\n",
      "Epoch 249/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 99820.4531 - classical_outs_loss: 6.9480 - inverse_pca_loss: 99813.5156 - val_loss: 83865.1016 - val_classical_outs_loss: 6.2412 - val_inverse_pca_loss: 83858.8516 - lr: 9.8518e-04\n",
      "Epoch 250/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 118482.0781 - classical_outs_loss: 7.1330 - inverse_pca_loss: 118474.9609 - val_loss: 118168.3594 - val_classical_outs_loss: 6.4970 - val_inverse_pca_loss: 118161.8672 - lr: 9.8512e-04\n",
      "Epoch 251/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 146335.6250 - classical_outs_loss: 7.3092 - inverse_pca_loss: 146328.3594 - val_loss: 137134.0000 - val_classical_outs_loss: 6.7345 - val_inverse_pca_loss: 137127.2656 - lr: 9.8506e-04\n",
      "Epoch 252/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 100108.2266 - classical_outs_loss: 6.6243 - inverse_pca_loss: 100101.5703 - val_loss: 91862.2500 - val_classical_outs_loss: 6.2187 - val_inverse_pca_loss: 91856.0312 - lr: 9.8500e-04\n",
      "Epoch 253/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 106202.2109 - classical_outs_loss: 6.9982 - inverse_pca_loss: 106195.2188 - val_loss: 60660.1094 - val_classical_outs_loss: 6.0311 - val_inverse_pca_loss: 60654.0781 - lr: 9.8494e-04\n",
      "Epoch 254/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 105306.9766 - classical_outs_loss: 6.7451 - inverse_pca_loss: 105300.2188 - val_loss: 69405.2422 - val_classical_outs_loss: 6.3669 - val_inverse_pca_loss: 69398.8828 - lr: 9.8488e-04\n",
      "Epoch 255/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 116108.5000 - classical_outs_loss: 7.4486 - inverse_pca_loss: 116101.0625 - val_loss: 123684.8125 - val_classical_outs_loss: 6.8414 - val_inverse_pca_loss: 123677.9766 - lr: 9.8483e-04\n",
      "Epoch 256/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 141032.2969 - classical_outs_loss: 6.8557 - inverse_pca_loss: 141025.3906 - val_loss: 61081.1172 - val_classical_outs_loss: 7.0424 - val_inverse_pca_loss: 61074.0742 - lr: 9.8477e-04\n",
      "Epoch 257/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 104420.8359 - classical_outs_loss: 6.6069 - inverse_pca_loss: 104414.2344 - val_loss: 65476.2109 - val_classical_outs_loss: 6.5311 - val_inverse_pca_loss: 65469.6758 - lr: 9.8471e-04\n",
      "Epoch 258/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 107008.9609 - classical_outs_loss: 6.8737 - inverse_pca_loss: 107002.0859 - val_loss: 91509.9453 - val_classical_outs_loss: 6.7151 - val_inverse_pca_loss: 91503.2266 - lr: 9.8465e-04\n",
      "Epoch 259/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 132547.0938 - classical_outs_loss: 7.1383 - inverse_pca_loss: 132539.9844 - val_loss: 125483.1094 - val_classical_outs_loss: 7.2254 - val_inverse_pca_loss: 125475.8828 - lr: 9.8459e-04\n",
      "Epoch 260/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 107116.3750 - classical_outs_loss: 6.8480 - inverse_pca_loss: 107109.5234 - val_loss: 254835.9531 - val_classical_outs_loss: 6.9663 - val_inverse_pca_loss: 254828.9688 - lr: 9.8453e-04\n",
      "Epoch 261/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 112048.3828 - classical_outs_loss: 6.5181 - inverse_pca_loss: 112041.8750 - val_loss: 109466.9922 - val_classical_outs_loss: 7.3769 - val_inverse_pca_loss: 109459.6172 - lr: 9.8447e-04\n",
      "Epoch 262/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 127815.6484 - classical_outs_loss: 6.9419 - inverse_pca_loss: 127808.7188 - val_loss: 108512.7656 - val_classical_outs_loss: 6.2677 - val_inverse_pca_loss: 108506.5000 - lr: 9.8441e-04\n",
      "Epoch 263/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 106751.9844 - classical_outs_loss: 6.9066 - inverse_pca_loss: 106745.1016 - val_loss: 71500.8828 - val_classical_outs_loss: 6.3586 - val_inverse_pca_loss: 71494.5312 - lr: 9.8435e-04\n",
      "Epoch 264/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 117567.2422 - classical_outs_loss: 7.0141 - inverse_pca_loss: 117560.2266 - val_loss: 112256.7344 - val_classical_outs_loss: 6.2551 - val_inverse_pca_loss: 112250.4766 - lr: 9.8429e-04\n",
      "Epoch 265/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 100065.1406 - classical_outs_loss: 6.6906 - inverse_pca_loss: 100058.4219 - val_loss: 71307.9844 - val_classical_outs_loss: 6.1991 - val_inverse_pca_loss: 71301.7891 - lr: 9.8424e-04\n",
      "Epoch 266/100000\n",
      "68/68 [==============================] - 1s 11ms/step - loss: 123857.8203 - classical_outs_loss: 6.9241 - inverse_pca_loss: 123850.9062 - val_loss: 62187.3555 - val_classical_outs_loss: 6.8935 - val_inverse_pca_loss: 62180.4648 - lr: 9.8418e-04\n",
      "Epoch 267/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 108116.7812 - classical_outs_loss: 6.7377 - inverse_pca_loss: 108110.0234 - val_loss: 60161.6836 - val_classical_outs_loss: 6.1839 - val_inverse_pca_loss: 60155.5000 - lr: 9.8412e-04\n",
      "Epoch 268/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 100592.9219 - classical_outs_loss: 6.5619 - inverse_pca_loss: 100586.3594 - val_loss: 237575.5469 - val_classical_outs_loss: 6.6988 - val_inverse_pca_loss: 237568.8594 - lr: 9.8406e-04\n",
      "Epoch 269/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 107914.9062 - classical_outs_loss: 6.7874 - inverse_pca_loss: 107908.0938 - val_loss: 405306.6250 - val_classical_outs_loss: 7.9341 - val_inverse_pca_loss: 405298.6875 - lr: 9.8400e-04\n",
      "Epoch 270/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 117335.8125 - classical_outs_loss: 6.6204 - inverse_pca_loss: 117329.1797 - val_loss: 362239.1562 - val_classical_outs_loss: 7.0421 - val_inverse_pca_loss: 362232.1250 - lr: 9.8394e-04\n",
      "Epoch 271/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 126775.6172 - classical_outs_loss: 7.2048 - inverse_pca_loss: 126768.4062 - val_loss: 111023.0078 - val_classical_outs_loss: 6.8387 - val_inverse_pca_loss: 111016.1641 - lr: 9.8388e-04\n",
      "Epoch 272/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 114843.4844 - classical_outs_loss: 6.4698 - inverse_pca_loss: 114836.9922 - val_loss: 40605.0430 - val_classical_outs_loss: 5.8225 - val_inverse_pca_loss: 40599.2227 - lr: 9.8382e-04\n",
      "Epoch 273/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 104935.3672 - classical_outs_loss: 6.8562 - inverse_pca_loss: 104928.5000 - val_loss: 96181.8359 - val_classical_outs_loss: 6.2243 - val_inverse_pca_loss: 96175.6172 - lr: 9.8376e-04\n",
      "Epoch 274/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 89278.1641 - classical_outs_loss: 6.3802 - inverse_pca_loss: 89271.7969 - val_loss: 42507.2891 - val_classical_outs_loss: 5.6710 - val_inverse_pca_loss: 42501.6211 - lr: 9.8370e-04\n",
      "Epoch 275/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 114473.7969 - classical_outs_loss: 6.7331 - inverse_pca_loss: 114467.0312 - val_loss: 73006.7578 - val_classical_outs_loss: 5.8997 - val_inverse_pca_loss: 73000.8516 - lr: 9.8364e-04\n",
      "Epoch 276/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 109299.8750 - classical_outs_loss: 6.5418 - inverse_pca_loss: 109293.3359 - val_loss: 157199.6719 - val_classical_outs_loss: 8.5197 - val_inverse_pca_loss: 157191.1562 - lr: 9.8359e-04\n",
      "Epoch 277/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 91858.3203 - classical_outs_loss: 6.7414 - inverse_pca_loss: 91851.5781 - val_loss: 84599.0625 - val_classical_outs_loss: 6.3109 - val_inverse_pca_loss: 84592.7578 - lr: 9.8353e-04\n",
      "Epoch 278/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 123786.3906 - classical_outs_loss: 6.4091 - inverse_pca_loss: 123779.9922 - val_loss: 123036.8828 - val_classical_outs_loss: 6.6102 - val_inverse_pca_loss: 123030.2656 - lr: 9.8347e-04\n",
      "Epoch 279/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 93787.1016 - classical_outs_loss: 6.7126 - inverse_pca_loss: 93780.3672 - val_loss: 100315.2812 - val_classical_outs_loss: 6.0185 - val_inverse_pca_loss: 100309.2734 - lr: 9.8341e-04\n",
      "Epoch 280/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 121364.0156 - classical_outs_loss: 6.7777 - inverse_pca_loss: 121357.2500 - val_loss: 87799.2578 - val_classical_outs_loss: 7.0381 - val_inverse_pca_loss: 87792.2188 - lr: 9.8335e-04\n",
      "Epoch 281/100000\n",
      "68/68 [==============================] - 1s 10ms/step - loss: 90078.1094 - classical_outs_loss: 6.5176 - inverse_pca_loss: 90071.6016 - val_loss: 39995.9453 - val_classical_outs_loss: 5.6860 - val_inverse_pca_loss: 39990.2617 - lr: 9.8329e-04\n",
      "Epoch 282/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 124781.0000 - classical_outs_loss: 6.5960 - inverse_pca_loss: 124774.3828 - val_loss: 108318.8516 - val_classical_outs_loss: 6.8022 - val_inverse_pca_loss: 108312.0469 - lr: 9.8323e-04\n",
      "Epoch 283/100000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 91722.3750 - classical_outs_loss: 6.9503 - inverse_pca_loss: 91715.4219 - val_loss: 273287.2812 - val_classical_outs_loss: 6.7189 - val_inverse_pca_loss: 273280.5312 - lr: 9.8317e-04\n",
      "Epoch 284/100000\n",
      "36/68 [==============>...............] - ETA: 0s - loss: 96787.7188 - classical_outs_loss: 6.0699 - inverse_pca_loss: 96781.6562  "
     ]
    }
   ],
   "source": [
    "## model_name\n",
    "model_name = 'fitchpork-duo'\n",
    "\n",
    "tb_dir = repo_dir + 'logs/fit/'\n",
    "model_dir = repo_dir + 'models/'\n",
    "\n",
    "## architecture variables\n",
    "stem_d_layers = 2\n",
    "stem_d_units = 128\n",
    "\n",
    "ctine_d_layers = 2\n",
    "ctine_d_units = 64\n",
    "\n",
    "atine_d_layers = 6\n",
    "atine_d_units = 128\n",
    "\n",
    "initial_lr = 0.001\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "######## stem\n",
    "#### input\n",
    "stem_input = keras.Input(shape=(len(inputs),))\n",
    "\n",
    "#### dense layers\n",
    "for stem_d_layer in range(stem_d_layers):\n",
    "    if stem_d_layer == 0:\n",
    "        stem = layers.Dense(stem_d_units, activation='elu')(stem_input)\n",
    "    else:\n",
    "        stem = layers.Dense(stem_d_units, activation='elu')(stem)\n",
    "\n",
    "######## classical tine\n",
    "#### dense layers\n",
    "for ctine_d_layer in range(ctine_d_layers):\n",
    "    if ctine_d_layer == 0:\n",
    "        ctine = layers.Dense(ctine_d_units, activation='elu')(stem)\n",
    "    else:\n",
    "        ctine = layers.Dense(ctine_d_units, activation='elu')(ctine)\n",
    "\n",
    "#### output\n",
    "ctine_out = layers.Dense(len(classical_outputs), name='classical_outs')(ctine)\n",
    "\n",
    "\n",
    "######## astero tine\n",
    "#### dense layers\n",
    "for atine_d_layer in range(atine_d_layers):\n",
    "    if atine_d_layer == 0:\n",
    "        atine = layers.Dense(atine_d_units, activation='elu')(stem)\n",
    "    else:\n",
    "        atine = layers.Dense(atine_d_units, activation='elu')(atine)\n",
    "\n",
    "#### output\n",
    "atine = layers.Dense(int(len(pca_components)))(atine)\n",
    "atine_out = InversePCA(pca_comps = pca_components, pca_mean = pca_mean, name='asteroseismic_outs')(atine)\n",
    "\n",
    "######## construct and fit\n",
    "model = keras.Model(inputs=stem_input, outputs=[ctine_out, atine_out], name=model_name)\n",
    "\n",
    "#### compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "  \n",
    "model.compile(loss=[WMSE(WMSE_weights[:3]), WMSE(WMSE_weights[3:])], optimizer=optimizer)\n",
    "\n",
    "#### fit model\n",
    "def scheduler(epoch, lr):\n",
    "    if lr < 1e-5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.00006) #<- changed from -0.00006!\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=0)\n",
    "                                                   \n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(model_dir + model_name + \".h5\",\n",
    "                                                 monitor= 'val_loss',\n",
    "                                                 save_best_only= True,\n",
    "                                                 save_freq='epoch')    \n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir+model_name) \n",
    "\n",
    "history = model.fit(df_train[inputs],\n",
    "                    [df_train[classical_outputs],df_train[astero_outputs]],\n",
    "                    validation_data=(df_val[inputs],[df_val[classical_outputs], df_val[astero_outputs]]),\n",
    "                    batch_size=32768,\n",
    "                    verbose=1,\n",
    "                    epochs=100000,\n",
    "                    callbacks=[lr_callback, cp_callback, tb_callback],\n",
    "                    shuffle=True\n",
    "                   ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c522cf-c55d-491f-b71d-29c1cc958367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
